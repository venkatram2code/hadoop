2015-01-20 02:35:56,627 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 02:52:25,926 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 02:54:19,529 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 02:58:43,804 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:09:55,001 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:11:09,718 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:14:28,771 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:32:27,988 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:33:42,245 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:34:53,309 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:37:16,692 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:37:17,216 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 03:37:17,235 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 03:37:17,242 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 03:37:17,247 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 03:47:53,115 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:47:53,537 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2015-01-20 03:47:53,545 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2015-01-20 03:47:53,930 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-01-20 03:47:53,935 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2015-01-20 03:47:53,977 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 5
2015-01-20 03:47:54,011 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:5
2015-01-20 03:47:54,260 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local408748985_0001
2015-01-20 03:47:54,298 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera408748985/.staging/job_local408748985_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 03:47:54,306 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera408748985/.staging/job_local408748985_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 03:47:54,589 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local408748985_0001/job_local408748985_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 03:47:54,598 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local408748985_0001/job_local408748985_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 03:47:54,621 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2015-01-20 03:47:54,622 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local408748985_0001
2015-01-20 03:47:54,635 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2015-01-20 03:47:54,651 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-01-20 03:47:54,776 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2015-01-20 03:47:54,778 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local408748985_0001_m_000000_0
2015-01-20 03:47:54,875 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 03:47:54,879 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq/seq1:0+155
2015-01-20 03:47:54,983 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 03:47:54,984 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 03:47:54,984 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 03:47:54,984 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 03:47:54,984 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 03:47:54,989 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 03:47:55,048 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2015-01-20 03:47:55,066 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2015-01-20 03:47:55,066 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 03:47:55,081 INFO org.apache.hadoop.mapred.Task: Task:attempt_local408748985_0001_m_000000_0 is done. And is in the process of committing
2015-01-20 03:47:55,090 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2015-01-20 03:47:55,090 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local408748985_0001_m_000000_0' done.
2015-01-20 03:47:55,090 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local408748985_0001_m_000000_0
2015-01-20 03:47:55,090 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local408748985_0001_m_000001_0
2015-01-20 03:47:55,092 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 03:47:55,094 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq/seq1~:0+13
2015-01-20 03:47:55,229 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 03:47:55,229 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 03:47:55,229 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 03:47:55,230 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 03:47:55,230 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 03:47:55,232 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 03:47:55,237 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader@2aa3d067
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.close(SequenceFileRecordReader.java:105)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.close(MapTask.java:520)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:1997)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2015-01-20 03:47:55,244 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 03:47:55,250 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local408748985_0001_m_000002_0
2015-01-20 03:47:55,252 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 03:47:55,254 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq/seq3~:0+0
2015-01-20 03:47:55,957 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 03:47:55,958 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 03:47:55,958 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 03:47:55,958 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 03:47:55,959 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 03:47:55,967 INFO org.apache.hadoop.mapreduce.Job: Job job_local408748985_0001 running in uber mode : false
2015-01-20 03:47:55,968 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 03:47:55,975 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader@597da8eb
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.close(SequenceFileRecordReader.java:105)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.close(MapTask.java:520)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:1997)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2015-01-20 03:47:55,976 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 03:47:55,983 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local408748985_0001_m_000003_0
2015-01-20 03:47:55,987 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 03:47:55,997 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq/seq4~:0+0
2015-01-20 03:47:56,002 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2015-01-20 03:47:56,269 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 03:47:56,383 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 03:47:56,384 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 03:47:56,384 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 03:47:56,384 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 03:47:56,388 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 03:47:56,390 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader@19be3a82
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.close(SequenceFileRecordReader.java:105)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.close(MapTask.java:520)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:1997)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2015-01-20 03:47:56,391 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 03:47:56,465 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local408748985_0001_m_000004_0
2015-01-20 03:47:56,469 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 03:47:56,587 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq/seq2~:0+0
2015-01-20 03:47:57,291 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 03:47:57,291 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 03:47:57,308 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 03:47:57,308 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 03:47:57,308 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 03:47:57,344 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 03:47:57,359 INFO org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader@4b48d148
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.close(SequenceFileRecordReader.java:105)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.close(MapTask.java:520)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:1997)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2015-01-20 03:47:57,360 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 03:47:57,370 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2015-01-20 03:47:57,376 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local408748985_0001
java.lang.Exception: java.io.IOException: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq/seq1~ not a SequenceFile
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq/seq1~ not a SequenceFile
	at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1850)
	at org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1810)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1759)
	at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1773)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader.initialize(SequenceFileRecordReader.java:54)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:545)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:783)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2015-01-20 03:47:58,294 INFO org.apache.hadoop.mapreduce.Job: Job job_local408748985_0001 failed with state FAILED due to: NA
2015-01-20 03:47:58,361 INFO org.apache.hadoop.mapreduce.Job: Counters: 20
	File System Counters
		FILE: Number of bytes read=899
		FILE: Number of bytes written=248596
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=128
		Combine input records=0
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=181403648
	File Input Format Counters 
		Bytes Read=167
2015-01-20 03:56:23,426 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:56:24,092 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 03:56:24,108 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 03:56:24,113 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 03:56:24,120 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 03:59:58,701 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 03:59:59,025 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2015-01-20 03:59:59,035 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2015-01-20 03:59:59,412 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-01-20 03:59:59,421 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2015-01-20 03:59:59,442 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2015-01-20 03:59:59,473 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2015-01-20 03:59:59,693 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1642211415_0001
2015-01-20 03:59:59,736 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera1642211415/.staging/job_local1642211415_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 03:59:59,749 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera1642211415/.staging/job_local1642211415_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 03:59:59,958 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local1642211415_0001/job_local1642211415_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 03:59:59,965 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local1642211415_0001/job_local1642211415_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 03:59:59,984 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2015-01-20 03:59:59,985 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1642211415_0001
2015-01-20 03:59:59,991 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2015-01-20 04:00:00,015 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-01-20 04:00:00,121 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2015-01-20 04:00:00,129 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1642211415_0001_m_000000_0
2015-01-20 04:00:00,211 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 04:00:00,218 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq_inter/seq1:0+155
2015-01-20 04:00:00,380 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 04:00:00,381 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 04:00:00,381 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 04:00:00,381 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 04:00:00,381 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 04:00:00,388 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 04:00:00,457 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2015-01-20 04:00:00,472 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2015-01-20 04:00:00,473 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 04:00:00,492 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1642211415_0001_m_000000_0 is done. And is in the process of committing
2015-01-20 04:00:00,504 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2015-01-20 04:00:00,504 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1642211415_0001_m_000000_0' done.
2015-01-20 04:00:00,504 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1642211415_0001_m_000000_0
2015-01-20 04:00:00,504 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2015-01-20 04:00:00,511 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2015-01-20 04:00:00,512 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1642211415_0001_r_000000_0
2015-01-20 04:00:00,520 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 04:00:00,523 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19576987
2015-01-20 04:00:00,537 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=626471744, maxSingleShuffleLimit=156617936, mergeThreshold=413471360, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2015-01-20 04:00:00,539 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1642211415_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2015-01-20 04:00:00,564 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1642211415_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2015-01-20 04:00:00,572 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1642211415_0001_m_000000_0
2015-01-20 04:00:00,572 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2015-01-20 04:00:00,573 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2015-01-20 04:00:00,574 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 04:00:00,575 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2015-01-20 04:00:00,582 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2015-01-20 04:00:00,583 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2015-01-20 04:00:00,584 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
2015-01-20 04:00:00,584 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2015-01-20 04:00:00,585 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2015-01-20 04:00:00,585 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2015-01-20 04:00:00,586 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2015-01-20 04:00:00,586 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 04:00:00,594 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2015-01-20 04:00:00,600 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1642211415_0001_r_000000_0 is done. And is in the process of committing
2015-01-20 04:00:00,602 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 04:00:00,602 INFO org.apache.hadoop.mapred.Task: Task attempt_local1642211415_0001_r_000000_0 is allowed to commit now
2015-01-20 04:00:00,603 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1642211415_0001_r_000000_0' to file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq_out/_temporary/0/task_local1642211415_0001_r_000000
2015-01-20 04:00:00,604 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2015-01-20 04:00:00,604 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1642211415_0001_r_000000_0' done.
2015-01-20 04:00:00,605 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1642211415_0001_r_000000_0
2015-01-20 04:00:00,605 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2015-01-20 04:00:00,994 INFO org.apache.hadoop.mapreduce.Job: Job job_local1642211415_0001 running in uber mode : false
2015-01-20 04:00:00,997 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2015-01-20 04:00:01,000 INFO org.apache.hadoop.mapreduce.Job: Job job_local1642211415_0001 completed successfully
2015-01-20 04:00:01,032 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=756
		FILE: Number of bytes written=498776
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=362807296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=167
	File Output Format Counters 
		Bytes Written=8
2015-01-20 04:06:21,782 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 04:06:22,156 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2015-01-20 04:06:22,158 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2015-01-20 04:06:22,551 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-01-20 04:06:22,557 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2015-01-20 04:06:22,575 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2015-01-20 04:06:22,604 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2015-01-20 04:06:22,796 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1332837338_0001
2015-01-20 04:06:22,894 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera1332837338/.staging/job_local1332837338_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 04:06:22,913 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera1332837338/.staging/job_local1332837338_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 04:06:23,192 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local1332837338_0001/job_local1332837338_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 04:06:23,197 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local1332837338_0001/job_local1332837338_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 04:06:23,203 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2015-01-20 04:06:23,204 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1332837338_0001
2015-01-20 04:06:23,208 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2015-01-20 04:06:23,217 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-01-20 04:06:23,276 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2015-01-20 04:06:23,277 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1332837338_0001_m_000000_0
2015-01-20 04:06:23,338 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 04:06:23,345 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq_inter/seq1:0+155
2015-01-20 04:06:23,474 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 04:06:23,474 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 04:06:23,474 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 04:06:23,474 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 04:06:23,474 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 04:06:23,480 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 04:06:23,580 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2015-01-20 04:06:23,595 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2015-01-20 04:06:23,596 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 04:06:23,596 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2015-01-20 04:06:23,596 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 11; bufvoid = 104857600
2015-01-20 04:06:23,597 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-01-20 04:06:23,605 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2015-01-20 04:06:23,610 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1332837338_0001_m_000000_0 is done. And is in the process of committing
2015-01-20 04:06:23,619 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2015-01-20 04:06:23,620 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1332837338_0001_m_000000_0' done.
2015-01-20 04:06:23,620 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1332837338_0001_m_000000_0
2015-01-20 04:06:23,620 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2015-01-20 04:06:23,626 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2015-01-20 04:06:23,627 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1332837338_0001_r_000000_0
2015-01-20 04:06:23,643 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 04:06:23,646 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19576987
2015-01-20 04:06:23,663 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=626471744, maxSingleShuffleLimit=156617936, mergeThreshold=413471360, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2015-01-20 04:06:23,666 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1332837338_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2015-01-20 04:06:23,703 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1332837338_0001_m_000000_0 decomp: 15 len: 19 to MEMORY
2015-01-20 04:06:23,710 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 15 bytes from map-output for attempt_local1332837338_0001_m_000000_0
2015-01-20 04:06:23,710 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->15
2015-01-20 04:06:23,714 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2015-01-20 04:06:23,715 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 04:06:23,716 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2015-01-20 04:06:23,724 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2015-01-20 04:06:23,725 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2015-01-20 04:06:23,727 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 15 bytes to disk to satisfy reduce memory limit
2015-01-20 04:06:23,727 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 19 bytes from disk
2015-01-20 04:06:23,728 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2015-01-20 04:06:23,728 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2015-01-20 04:06:23,729 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2015-01-20 04:06:23,729 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 04:06:23,737 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2015-01-20 04:06:23,745 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1332837338_0001_r_000000_0 is done. And is in the process of committing
2015-01-20 04:06:23,748 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 04:06:23,748 INFO org.apache.hadoop.mapred.Task: Task attempt_local1332837338_0001_r_000000_0 is allowed to commit now
2015-01-20 04:06:23,749 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1332837338_0001_r_000000_0' to file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq_out/_temporary/0/task_local1332837338_0001_r_000000
2015-01-20 04:06:23,750 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2015-01-20 04:06:23,750 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1332837338_0001_r_000000_0' done.
2015-01-20 04:06:23,751 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1332837338_0001_r_000000_0
2015-01-20 04:06:23,751 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2015-01-20 04:06:24,207 INFO org.apache.hadoop.mapreduce.Job: Job job_local1332837338_0001 running in uber mode : false
2015-01-20 04:06:24,212 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2015-01-20 04:06:24,215 INFO org.apache.hadoop.mapreduce.Job: Job job_local1332837338_0001 completed successfully
2015-01-20 04:06:24,250 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=782
		FILE: Number of bytes written=498831
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=11
		Map output materialized bytes=19
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=19
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=362807296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=167
	File Output Format Counters 
		Bytes Written=24
2015-01-20 04:08:26,560 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 04:08:27,164 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 04:08:27,181 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 04:08:27,189 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 04:08:27,196 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 13:55:21,878 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 13:55:22,685 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2015-01-20 13:55:22,697 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2015-01-20 13:55:23,408 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-01-20 13:55:23,420 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2015-01-20 13:55:23,501 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2015-01-20 13:55:23,574 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2015-01-20 13:55:23,969 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1165392163_0001
2015-01-20 13:55:24,076 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera1165392163/.staging/job_local1165392163_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 13:55:24,088 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera1165392163/.staging/job_local1165392163_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 13:55:24,627 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local1165392163_0001/job_local1165392163_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 13:55:24,645 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local1165392163_0001/job_local1165392163_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 13:55:24,678 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2015-01-20 13:55:24,683 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1165392163_0001
2015-01-20 13:55:24,688 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2015-01-20 13:55:24,728 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-01-20 13:55:24,889 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2015-01-20 13:55:24,890 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1165392163_0001_m_000000_0
2015-01-20 13:55:24,984 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 13:55:24,999 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq_inter/seq1:0+155
2015-01-20 13:55:25,702 INFO org.apache.hadoop.mapreduce.Job: Job job_local1165392163_0001 running in uber mode : false
2015-01-20 13:55:26,019 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 13:55:26,024 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 13:55:26,025 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 13:55:26,025 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 13:55:26,025 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 13:55:26,083 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2015-01-20 13:55:26,167 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 13:55:26,379 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2015-01-20 13:55:26,403 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2015-01-20 13:55:26,404 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 13:55:26,404 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2015-01-20 13:55:26,404 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 11; bufvoid = 104857600
2015-01-20 13:55:26,404 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-01-20 13:55:26,421 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2015-01-20 13:55:26,432 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1165392163_0001_m_000000_0 is done. And is in the process of committing
2015-01-20 13:55:26,452 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2015-01-20 13:55:26,452 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1165392163_0001_m_000000_0' done.
2015-01-20 13:55:26,453 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1165392163_0001_m_000000_0
2015-01-20 13:55:26,453 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2015-01-20 13:55:26,459 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2015-01-20 13:55:26,460 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1165392163_0001_r_000000_0
2015-01-20 13:55:26,474 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 13:55:26,481 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@508e2d21
2015-01-20 13:55:26,510 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=626471744, maxSingleShuffleLimit=156617936, mergeThreshold=413471360, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2015-01-20 13:55:26,514 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1165392163_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2015-01-20 13:55:26,566 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1165392163_0001_m_000000_0 decomp: 15 len: 19 to MEMORY
2015-01-20 13:55:26,587 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 15 bytes from map-output for attempt_local1165392163_0001_m_000000_0
2015-01-20 13:55:26,587 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->15
2015-01-20 13:55:26,591 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2015-01-20 13:55:26,593 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 13:55:26,593 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2015-01-20 13:55:26,606 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2015-01-20 13:55:26,606 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2015-01-20 13:55:26,609 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 15 bytes to disk to satisfy reduce memory limit
2015-01-20 13:55:26,609 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 19 bytes from disk
2015-01-20 13:55:26,611 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2015-01-20 13:55:26,611 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2015-01-20 13:55:26,612 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2015-01-20 13:55:26,613 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 13:55:26,627 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2015-01-20 13:55:26,635 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1165392163_0001_r_000000_0 is done. And is in the process of committing
2015-01-20 13:55:26,638 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 13:55:26,638 INFO org.apache.hadoop.mapred.Task: Task attempt_local1165392163_0001_r_000000_0 is allowed to commit now
2015-01-20 13:55:26,640 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1165392163_0001_r_000000_0' to file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq_out/_temporary/0/task_local1165392163_0001_r_000000
2015-01-20 13:55:26,641 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2015-01-20 13:55:26,641 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1165392163_0001_r_000000_0' done.
2015-01-20 13:55:26,642 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1165392163_0001_r_000000_0
2015-01-20 13:55:26,642 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2015-01-20 13:55:27,160 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2015-01-20 13:55:27,162 INFO org.apache.hadoop.mapreduce.Job: Job job_local1165392163_0001 completed successfully
2015-01-20 13:55:27,232 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=782
		FILE: Number of bytes written=498831
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=11
		Map output materialized bytes=19
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=19
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=362807296
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=167
	File Output Format Counters 
		Bytes Written=24
2015-01-20 14:00:51,821 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 14:00:53,107 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 14:00:53,147 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 14:00:53,161 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 14:00:53,174 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 14:01:17,055 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 14:01:17,665 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2015-01-20 14:01:17,672 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2015-01-20 14:01:18,226 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2015-01-20 14:01:18,231 WARN org.apache.hadoop.mapreduce.JobSubmitter: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2015-01-20 14:01:18,266 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2015-01-20 14:01:18,311 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2015-01-20 14:01:18,600 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local498204683_0001
2015-01-20 14:01:18,657 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera498204683/.staging/job_local498204683_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 14:01:18,669 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/staging/cloudera498204683/.staging/job_local498204683_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 14:01:18,971 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local498204683_0001/job_local498204683_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
2015-01-20 14:01:18,976 WARN org.apache.hadoop.conf.Configuration: file:/tmp/hadoop-cloudera/mapred/local/localRunner/cloudera/job_local498204683_0001/job_local498204683_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
2015-01-20 14:01:18,983 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2015-01-20 14:01:18,984 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local498204683_0001
2015-01-20 14:01:18,990 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2015-01-20 14:01:19,003 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2015-01-20 14:01:19,096 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2015-01-20 14:01:19,098 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local498204683_0001_m_000000_0
2015-01-20 14:01:19,180 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 14:01:19,188 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq_inter/seq1:0+155
2015-01-20 14:01:19,565 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2015-01-20 14:01:19,566 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2015-01-20 14:01:19,566 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2015-01-20 14:01:19,566 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2015-01-20 14:01:19,566 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2015-01-20 14:01:19,699 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2015-01-20 14:01:19,922 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new decompressor [.deflate]
2015-01-20 14:01:19,944 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2015-01-20 14:01:19,945 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2015-01-20 14:01:19,946 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2015-01-20 14:01:19,946 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 11; bufvoid = 104857600
2015-01-20 14:01:19,946 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2015-01-20 14:01:19,961 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2015-01-20 14:01:19,970 INFO org.apache.hadoop.mapred.Task: Task:attempt_local498204683_0001_m_000000_0 is done. And is in the process of committing
2015-01-20 14:01:19,988 INFO org.apache.hadoop.mapreduce.Job: Job job_local498204683_0001 running in uber mode : false
2015-01-20 14:01:19,992 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2015-01-20 14:01:20,001 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2015-01-20 14:01:20,002 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local498204683_0001_m_000000_0' done.
2015-01-20 14:01:20,002 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local498204683_0001_m_000000_0
2015-01-20 14:01:20,003 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2015-01-20 14:01:20,010 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2015-01-20 14:01:20,011 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local498204683_0001_r_000000_0
2015-01-20 14:01:20,034 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2015-01-20 14:01:20,043 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4fdab00b
2015-01-20 14:01:20,071 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=626471744, maxSingleShuffleLimit=156617936, mergeThreshold=413471360, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2015-01-20 14:01:20,102 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local498204683_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2015-01-20 14:01:20,165 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local498204683_0001_m_000000_0 decomp: 15 len: 19 to MEMORY
2015-01-20 14:01:20,182 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 15 bytes from map-output for attempt_local498204683_0001_m_000000_0
2015-01-20 14:01:20,183 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 15, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->15
2015-01-20 14:01:20,186 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2015-01-20 14:01:20,188 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 14:01:20,188 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2015-01-20 14:01:20,200 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2015-01-20 14:01:20,200 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2015-01-20 14:01:20,202 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 15 bytes to disk to satisfy reduce memory limit
2015-01-20 14:01:20,203 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 19 bytes from disk
2015-01-20 14:01:20,205 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2015-01-20 14:01:20,205 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2015-01-20 14:01:20,206 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2015-01-20 14:01:20,207 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 14:01:20,225 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2015-01-20 14:01:20,233 INFO org.apache.hadoop.mapred.Task: Task:attempt_local498204683_0001_r_000000_0 is done. And is in the process of committing
2015-01-20 14:01:20,236 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2015-01-20 14:01:20,236 INFO org.apache.hadoop.mapred.Task: Task attempt_local498204683_0001_r_000000_0 is allowed to commit now
2015-01-20 14:01:20,237 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local498204683_0001_r_000000_0' to file:/home/cloudera/Desktop/localhadoop/seqchapter/readseq_out/_temporary/0/task_local498204683_0001_r_000000
2015-01-20 14:01:20,239 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2015-01-20 14:01:20,239 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local498204683_0001_r_000000_0' done.
2015-01-20 14:01:20,240 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local498204683_0001_r_000000_0
2015-01-20 14:01:20,240 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2015-01-20 14:01:21,001 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2015-01-20 14:01:21,003 INFO org.apache.hadoop.mapreduce.Job: Job job_local498204683_0001 completed successfully
2015-01-20 14:01:21,064 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=782
		FILE: Number of bytes written=496199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=11
		Map output materialized bytes=19
		Input split bytes=134
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=19
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331350016
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=167
	File Output Format Counters 
		Bytes Written=24
2015-01-20 14:01:51,608 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-01-20 14:01:52,522 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 14:01:52,541 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 14:01:52,548 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
2015-01-20 14:01:52,556 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor [.deflate]
